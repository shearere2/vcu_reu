{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shearere2/vcu_reu/blob/main/XGBOOST_FRAMEWORK_ETHAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('xgboost')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mV0m8cwFS9m",
        "outputId": "c60d4942-4406-4181-889f-1ce75915b1bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('estimatr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCH4k6IpCF1u",
        "outputId": "64b57f9a-4c8e-41d3-d811-b816b6659244"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘Formula’, ‘Rcpp’, ‘RcppEigen’\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"dplyr\") # this is going to be for binarizing the predictor columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvX02ZSaARuc",
        "outputId": "d5f3e2c2-84a4-4034-a88b-a02a76304822"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(dplyr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD_mAj35ATCF",
        "outputId": "ee7eca66-5f48-47bf-de17-517720b78696"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(xgboost)"
      ],
      "metadata": {
        "id": "gDzzsHy0HlTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82a944a-9196-4909-9838-0670f501fcfa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Attaching package: ‘xgboost’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:dplyr’:\n",
            "\n",
            "    slice\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(estimatr)"
      ],
      "metadata": {
        "id": "ZRcufS67IKHp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CISGENDER WOMEN SUBGROUP"
      ],
      "metadata": {
        "id": "5QdDDlf8OlpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using GPA as primary predictor"
      ],
      "metadata": {
        "id": "AVgiP8YlGzkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('gender_female.csv')\n",
        "rownames(data.intake) <- data.intake$record_id"
      ],
      "metadata": {
        "id": "lL_NKhqwOo3X"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}"
      ],
      "metadata": {
        "id": "lLWYGIBm3qN0"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL"
      ],
      "metadata": {
        "id": "SneJ2kqxO7gD"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])"
      ],
      "metadata": {
        "id": "YSixaQ7ZO8bM"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.intake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b0BK_JmHO_Ks",
        "outputId": "7101ea3a-9c6c-4891-e8e9-e677edc00edc",
        "collapsed": true
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 227 × 55</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>gpa_thresh3_0</th><th scope=col>role_family</th><th scope=col>role_friend</th><th scope=col>role_sigother</th><th scope=col>role_other</th><th scope=col>has_mother</th><th scope=col>has_father</th><th scope=col>stem_notstem</th><th scope=col>edu.r_count</th><th scope=col>edu.i_count</th><th scope=col>⋯</th><th scope=col>covid_edu</th><th scope=col>ptsd_score</th><th scope=col>trauma_sum</th><th scope=col>mh_scale</th><th scope=col>ss_friend</th><th scope=col>ss_family</th><th scope=col>ss_sigother</th><th scope=col>ss_community</th><th scope=col>age</th><th scope=col>first_gen</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>4</td><td>⋯</td><td> 6</td><td> 0</td><td>13</td><td>0.04761905</td><td>5.666667</td><td>5.50</td><td>5.50</td><td>4.75</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td> 5</td><td>15</td><td>10</td><td>0.80952381</td><td>4.666667</td><td>5.50</td><td>5.50</td><td>4.75</td><td>29</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>2</td><td>2</td><td>⋯</td><td> 1</td><td> 3</td><td>10</td><td>0.09523809</td><td>5.666667</td><td>5.50</td><td>5.50</td><td>5.50</td><td>53</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>3</td><td>⋯</td><td> 7</td><td> 0</td><td> 7</td><td>0.28571429</td><td>5.666667</td><td>5.50</td><td>5.50</td><td>5.00</td><td>46</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>2</td><td>2</td><td>⋯</td><td> 2</td><td> 8</td><td>12</td><td>0.23809524</td><td>5.333333</td><td>3.75</td><td>5.50</td><td>4.50</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>7</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>2</td><td>4</td><td>⋯</td><td> 2</td><td> 4</td><td> 9</td><td>0.14285714</td><td>5.333333</td><td>4.75</td><td>5.50</td><td>5.00</td><td>28</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>2</td><td>⋯</td><td> 0</td><td> 0</td><td>12</td><td>0.14285714</td><td>5.666667</td><td>5.50</td><td>5.50</td><td>3.75</td><td>55</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>9</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>3</td><td>3</td><td>⋯</td><td> 3</td><td>15</td><td> 8</td><td>1.04761905</td><td>4.666667</td><td>5.25</td><td>5.50</td><td>5.25</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3</td><td>⋯</td><td> 8</td><td>40</td><td> 5</td><td>0.42857143</td><td>5.333333</td><td>4.25</td><td>4.50</td><td>3.50</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>11</th><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td> 7</td><td>19</td><td>11</td><td>0.57142857</td><td>4.333333</td><td>5.25</td><td>5.50</td><td>4.75</td><td>38</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>12</th><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>4</td><td>⋯</td><td> 7</td><td>11</td><td> 8</td><td>0.19047619</td><td>5.333333</td><td>4.75</td><td>5.50</td><td>5.25</td><td>26</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>2</td><td>⋯</td><td> 7</td><td>10</td><td>10</td><td>0.33333333</td><td>5.666667</td><td>2.75</td><td>5.50</td><td>5.00</td><td>32</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>15</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>⋯</td><td>10</td><td>29</td><td> 2</td><td>0.80952381</td><td>4.333333</td><td>3.25</td><td>4.50</td><td>5.25</td><td>38</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>17</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>⋯</td><td> 7</td><td> 8</td><td>11</td><td>0.33333333</td><td>5.666667</td><td>5.25</td><td>5.50</td><td>5.50</td><td>42</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>18</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5</td><td>6</td><td>⋯</td><td> 6</td><td>22</td><td>10</td><td>1.00000000</td><td>5.000000</td><td>4.00</td><td>5.50</td><td>4.25</td><td>38</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>24</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>4</td><td>⋯</td><td> 7</td><td>15</td><td>13</td><td>0.52380952</td><td>4.333333</td><td>5.00</td><td>5.50</td><td>5.25</td><td>30</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>27</th><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2</td><td>2</td><td>⋯</td><td>10</td><td>15</td><td> 5</td><td>0.66666667</td><td>5.666667</td><td>4.75</td><td>4.50</td><td>3.50</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>29</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>5</td><td>⋯</td><td> 3</td><td>40</td><td> 9</td><td>1.09523810</td><td>3.333333</td><td>3.25</td><td>3.25</td><td>2.75</td><td>22</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>30</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>⋯</td><td> 8</td><td>21</td><td>11</td><td>0.52380952</td><td>5.666667</td><td>5.00</td><td>5.50</td><td>3.00</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>33</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>4</td><td>4</td><td>⋯</td><td> 8</td><td>17</td><td> 8</td><td>0.23809524</td><td>3.666667</td><td>4.00</td><td>2.00</td><td>3.50</td><td>31</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>36</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>4</td><td>4</td><td>⋯</td><td> 9</td><td>34</td><td>11</td><td>0.85714286</td><td>5.666667</td><td>2.50</td><td>3.75</td><td>3.00</td><td>23</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>37</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td> 6</td><td>30</td><td> 8</td><td>0.52380952</td><td>4.000000</td><td>5.50</td><td>5.00</td><td>3.50</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>39</th><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>⋯</td><td> 8</td><td>53</td><td> 8</td><td>1.47619048</td><td>5.666667</td><td>4.50</td><td>5.50</td><td>3.75</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>45</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2</td><td>4</td><td>⋯</td><td> 6</td><td>21</td><td>11</td><td>0.76190476</td><td>5.666667</td><td>5.50</td><td>5.50</td><td>5.50</td><td>21</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>46</th><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>2</td><td>2</td><td>⋯</td><td> 5</td><td>64</td><td> 7</td><td>2.57142857</td><td>1.666667</td><td>2.25</td><td>3.50</td><td>3.00</td><td>19</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>47</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>⋯</td><td> 7</td><td>34</td><td> 8</td><td>0.95238095</td><td>5.000000</td><td>4.00</td><td>5.25</td><td>4.25</td><td>20</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>49</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>3</td><td>⋯</td><td>10</td><td>24</td><td>11</td><td>0.61904762</td><td>5.666667</td><td>5.50</td><td>5.25</td><td>4.00</td><td>32</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>50</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>⋯</td><td> 6</td><td> 9</td><td>14</td><td>0.66666667</td><td>5.333333</td><td>4.00</td><td>5.50</td><td>5.25</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>52</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>2</td><td>⋯</td><td> 3</td><td>48</td><td> 8</td><td>0.66666667</td><td>5.333333</td><td>3.75</td><td>4.00</td><td>5.50</td><td>20</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>53</th><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>⋯</td><td> 3</td><td>10</td><td>11</td><td>0.61904762</td><td>5.666667</td><td>5.25</td><td>5.50</td><td>4.00</td><td>29</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
              "\t<tr><th scope=row>347</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>⋯</td><td> 8</td><td>12</td><td>10</td><td>0.71428571</td><td>5.3333333</td><td>5.25</td><td>5.50</td><td>4.50</td><td>22</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>350</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>2</td><td>2</td><td>⋯</td><td> 9</td><td> 0</td><td>10</td><td>0.19047619</td><td>4.6666667</td><td>4.25</td><td>5.50</td><td>5.00</td><td>24</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>354</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>2</td><td>⋯</td><td> 7</td><td>26</td><td> 5</td><td>1.23809524</td><td>5.3333333</td><td>3.25</td><td>4.25</td><td>5.25</td><td>21</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>355</th><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>10</td><td>34</td><td>10</td><td>1.04761905</td><td>5.6666667</td><td>1.50</td><td>5.50</td><td>5.25</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>356</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>⋯</td><td> 6</td><td> 1</td><td>10</td><td>0.09523809</td><td>5.6666667</td><td>5.25</td><td>5.50</td><td>5.50</td><td>23</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>357</th><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>⋯</td><td> 7</td><td>26</td><td>11</td><td>0.52380952</td><td>4.0000000</td><td>3.50</td><td>3.00</td><td>3.50</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>358</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>3</td><td>⋯</td><td> 7</td><td>15</td><td>10</td><td>0.19047619</td><td>5.3333333</td><td>4.75</td><td>5.25</td><td>4.50</td><td>21</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>359</th><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2</td><td>1</td><td>⋯</td><td> 6</td><td>11</td><td>10</td><td>0.57142857</td><td>4.0000000</td><td>3.25</td><td>5.25</td><td>4.75</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>362</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>⋯</td><td>10</td><td>35</td><td> 6</td><td>0.38095238</td><td>2.3333333</td><td>2.00</td><td>3.00</td><td>2.75</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>363</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td> 6</td><td>17</td><td>10</td><td>0.66666667</td><td>5.3333333</td><td>4.50</td><td>5.50</td><td>4.75</td><td>22</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>365</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>2</td><td>1</td><td>⋯</td><td> 7</td><td> 8</td><td> 8</td><td>0.19047619</td><td>5.0000000</td><td>3.00</td><td>5.50</td><td>4.00</td><td>23</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>366</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>2</td><td>4</td><td>⋯</td><td>10</td><td>24</td><td> 9</td><td>1.09523810</td><td>5.6666667</td><td>1.75</td><td>5.00</td><td>1.25</td><td>21</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>367</th><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>3</td><td>⋯</td><td> 0</td><td> 3</td><td> 6</td><td>0.09523809</td><td>0.6666667</td><td>0.75</td><td>0.50</td><td>0.50</td><td>20</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>370</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>5</td><td>⋯</td><td>10</td><td>20</td><td> 9</td><td>2.00000000</td><td>3.6666667</td><td>2.75</td><td>2.75</td><td>4.25</td><td>21</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>375</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>2</td><td>⋯</td><td> 8</td><td>11</td><td> 8</td><td>0.85714286</td><td>4.6666667</td><td>5.00</td><td>5.25</td><td>5.00</td><td>22</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>377</th><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>3</td><td>⋯</td><td>10</td><td>27</td><td>12</td><td>0.71428571</td><td>5.6666667</td><td>2.50</td><td>3.25</td><td>3.00</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>378</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td>⋯</td><td> 7</td><td>42</td><td> 9</td><td>1.80952381</td><td>4.6666667</td><td>1.75</td><td>2.00</td><td>3.50</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>380</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>3</td><td>1</td><td>⋯</td><td> 8</td><td> 4</td><td>10</td><td>1.14285714</td><td>4.3333333</td><td>3.50</td><td>1.00</td><td>4.00</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>381</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>3</td><td>4</td><td>⋯</td><td> 8</td><td> 3</td><td>14</td><td>0.04761905</td><td>5.6666667</td><td>5.50</td><td>5.50</td><td>3.75</td><td>21</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>383</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>4</td><td>4</td><td>⋯</td><td>10</td><td>57</td><td> 9</td><td>1.95238095</td><td>4.6666667</td><td>3.75</td><td>3.75</td><td>4.25</td><td>21</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>385</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>3</td><td>3</td><td>⋯</td><td> 9</td><td>39</td><td> 8</td><td>0.90476190</td><td>5.3333333</td><td>5.00</td><td>5.00</td><td>4.50</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>386</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>⋯</td><td> 8</td><td> 3</td><td>11</td><td>0.09523809</td><td>5.0000000</td><td>2.75</td><td>3.50</td><td>4.25</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>387</th><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2</td><td>2</td><td>⋯</td><td> 8</td><td> 4</td><td>13</td><td>0.04761905</td><td>5.3333333</td><td>5.50</td><td>5.50</td><td>5.00</td><td>21</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>392</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>⋯</td><td> 6</td><td>21</td><td> 9</td><td>0.57142857</td><td>4.0000000</td><td>4.00</td><td>4.50</td><td>3.50</td><td>22</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>395</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>⋯</td><td> 0</td><td> 0</td><td>10</td><td>0.00000000</td><td>5.3333333</td><td>5.50</td><td>5.50</td><td>3.25</td><td>63</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>398</th><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>4</td><td>⋯</td><td>10</td><td>61</td><td>11</td><td>2.09523810</td><td>3.3333333</td><td>2.75</td><td>3.00</td><td>2.75</td><td>21</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>399</th><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>⋯</td><td> 8</td><td>37</td><td> 9</td><td>1.28571429</td><td>5.6666667</td><td>4.25</td><td>5.25</td><td>4.75</td><td>19</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>401</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2</td><td>2</td><td>⋯</td><td>10</td><td>64</td><td> 8</td><td>2.57142857</td><td>4.0000000</td><td>0.50</td><td>1.25</td><td>3.75</td><td>22</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>402</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>3</td><td>3</td><td>⋯</td><td> 7</td><td>34</td><td>11</td><td>0.80952381</td><td>1.3333333</td><td>2.75</td><td>1.50</td><td>2.25</td><td> 0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>403</th><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>⋯</td><td>10</td><td>57</td><td> 9</td><td>2.66666667</td><td>4.0000000</td><td>1.25</td><td>4.00</td><td>3.75</td><td>22</td><td>1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 227 × 55\n\n| <!--/--> | gpa_thresh3_0 &lt;int&gt; | role_family &lt;int&gt; | role_friend &lt;int&gt; | role_sigother &lt;int&gt; | role_other &lt;int&gt; | has_mother &lt;int&gt; | has_father &lt;int&gt; | stem_notstem &lt;int&gt; | edu.r_count &lt;int&gt; | edu.i_count &lt;int&gt; | ⋯ ⋯ | covid_edu &lt;int&gt; | ptsd_score &lt;int&gt; | trauma_sum &lt;int&gt; | mh_scale &lt;dbl&gt; | ss_friend &lt;dbl&gt; | ss_family &lt;dbl&gt; | ss_sigother &lt;dbl&gt; | ss_community &lt;dbl&gt; | age &lt;dbl&gt; | first_gen &lt;int&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 4 | ⋯ |  6 |  0 | 13 | 0.04761905 | 5.666667 | 5.50 | 5.50 | 4.75 |  0 | 0 |\n| 2 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | ⋯ |  5 | 15 | 10 | 0.80952381 | 4.666667 | 5.50 | 5.50 | 4.75 | 29 | 0 |\n| 3 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 2 | 2 | ⋯ |  1 |  3 | 10 | 0.09523809 | 5.666667 | 5.50 | 5.50 | 5.50 | 53 | 0 |\n| 4 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 3 | ⋯ |  7 |  0 |  7 | 0.28571429 | 5.666667 | 5.50 | 5.50 | 5.00 | 46 | 0 |\n| 6 | 0 | 1 | 1 | 0 | 0 | 1 | 0 | 0 | 2 | 2 | ⋯ |  2 |  8 | 12 | 0.23809524 | 5.333333 | 3.75 | 5.50 | 4.50 |  0 | 0 |\n| 7 | 0 | 1 | 0 | 0 | 0 | 1 | 1 | 0 | 2 | 4 | ⋯ |  2 |  4 |  9 | 0.14285714 | 5.333333 | 4.75 | 5.50 | 5.00 | 28 | 0 |\n| 8 | 0 | 1 | 1 | 1 | 0 | 1 | 0 | 0 | 1 | 2 | ⋯ |  0 |  0 | 12 | 0.14285714 | 5.666667 | 5.50 | 5.50 | 3.75 | 55 | 0 |\n| 9 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 3 | 3 | ⋯ |  3 | 15 |  8 | 1.04761905 | 4.666667 | 5.25 | 5.50 | 5.25 |  0 | 0 |\n| 10 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 3 | ⋯ |  8 | 40 |  5 | 0.42857143 | 5.333333 | 4.25 | 4.50 | 3.50 |  0 | 0 |\n| 11 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ |  7 | 19 | 11 | 0.57142857 | 4.333333 | 5.25 | 5.50 | 4.75 | 38 | 0 |\n| 12 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 3 | 4 | ⋯ |  7 | 11 |  8 | 0.19047619 | 5.333333 | 4.75 | 5.50 | 5.25 | 26 | 0 |\n| 14 | 0 | 1 | 1 | 1 | 0 | 1 | 0 | 0 | 1 | 2 | ⋯ |  7 | 10 | 10 | 0.33333333 | 5.666667 | 2.75 | 5.50 | 5.00 | 32 | 0 |\n| 15 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | ⋯ | 10 | 29 |  2 | 0.80952381 | 4.333333 | 3.25 | 4.50 | 5.25 | 38 | 0 |\n| 17 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | ⋯ |  7 |  8 | 11 | 0.33333333 | 5.666667 | 5.25 | 5.50 | 5.50 | 42 | 1 |\n| 18 | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 5 | 6 | ⋯ |  6 | 22 | 10 | 1.00000000 | 5.000000 | 4.00 | 5.50 | 4.25 | 38 | 0 |\n| 24 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 1 | 1 | 4 | ⋯ |  7 | 15 | 13 | 0.52380952 | 4.333333 | 5.00 | 5.50 | 5.25 | 30 | 0 |\n| 27 | 1 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 2 | 2 | ⋯ | 10 | 15 |  5 | 0.66666667 | 5.666667 | 4.75 | 4.50 | 3.50 |  0 | 0 |\n| 29 | 1 | 1 | 1 | 1 | 0 | 1 | 0 | 1 | 1 | 5 | ⋯ |  3 | 40 |  9 | 1.09523810 | 3.333333 | 3.25 | 3.25 | 2.75 | 22 | 0 |\n| 30 | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 2 | ⋯ |  8 | 21 | 11 | 0.52380952 | 5.666667 | 5.00 | 5.50 | 3.00 |  0 | 0 |\n| 33 | 1 | 1 | 1 | 1 | 0 | 1 | 0 | 1 | 4 | 4 | ⋯ |  8 | 17 |  8 | 0.23809524 | 3.666667 | 4.00 | 2.00 | 3.50 | 31 | 0 |\n| 36 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 4 | 4 | ⋯ |  9 | 34 | 11 | 0.85714286 | 5.666667 | 2.50 | 3.75 | 3.00 | 23 | 0 |\n| 37 | 0 | 1 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | ⋯ |  6 | 30 |  8 | 0.52380952 | 4.000000 | 5.50 | 5.00 | 3.50 |  0 | 0 |\n| 39 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 1 | ⋯ |  8 | 53 |  8 | 1.47619048 | 5.666667 | 4.50 | 5.50 | 3.75 |  0 | 0 |\n| 45 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 2 | 4 | ⋯ |  6 | 21 | 11 | 0.76190476 | 5.666667 | 5.50 | 5.50 | 5.50 | 21 | 0 |\n| 46 | 0 | 1 | 0 | 1 | 0 | 1 | 1 | 0 | 2 | 2 | ⋯ |  5 | 64 |  7 | 2.57142857 | 1.666667 | 2.25 | 3.50 | 3.00 | 19 | 0 |\n| 47 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 1 | 0 | 1 | ⋯ |  7 | 34 |  8 | 0.95238095 | 5.000000 | 4.00 | 5.25 | 4.25 | 20 | 0 |\n| 49 | 0 | 1 | 1 | 1 | 0 | 1 | 0 | 1 | 0 | 3 | ⋯ | 10 | 24 | 11 | 0.61904762 | 5.666667 | 5.50 | 5.25 | 4.00 | 32 | 0 |\n| 50 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 1 | 2 | ⋯ |  6 |  9 | 14 | 0.66666667 | 5.333333 | 4.00 | 5.50 | 5.25 |  0 | 0 |\n| 52 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 2 | 2 | ⋯ |  3 | 48 |  8 | 0.66666667 | 5.333333 | 3.75 | 4.00 | 5.50 | 20 | 0 |\n| 53 | 1 | 1 | 1 | 0 | 1 | 0 | 0 | 1 | 1 | 1 | ⋯ |  3 | 10 | 11 | 0.61904762 | 5.666667 | 5.25 | 5.50 | 4.00 | 29 | 1 |\n| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n| 347 | 0 | 1 | 1 | 0 | 0 | 1 | 0 | 1 | 1 | 1 | ⋯ |  8 | 12 | 10 | 0.71428571 | 5.3333333 | 5.25 | 5.50 | 4.50 | 22 | 1 |\n| 350 | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 2 | 2 | ⋯ |  9 |  0 | 10 | 0.19047619 | 4.6666667 | 4.25 | 5.50 | 5.00 | 24 | 0 |\n| 354 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 2 | 2 | ⋯ |  7 | 26 |  5 | 1.23809524 | 5.3333333 | 3.25 | 4.25 | 5.25 | 21 | 0 |\n| 355 | 1 | 1 | 0 | 1 | 0 | 1 | 1 | 0 | 0 | 0 | ⋯ | 10 | 34 | 10 | 1.04761905 | 5.6666667 | 1.50 | 5.50 | 5.25 |  0 | 0 |\n| 356 | 1 | 1 | 1 | 1 | 0 | 1 | 0 | 0 | 1 | 1 | ⋯ |  6 |  1 | 10 | 0.09523809 | 5.6666667 | 5.25 | 5.50 | 5.50 | 23 | 0 |\n| 357 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | ⋯ |  7 | 26 | 11 | 0.52380952 | 4.0000000 | 3.50 | 3.00 | 3.50 |  0 | 0 |\n| 358 | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 3 | ⋯ |  7 | 15 | 10 | 0.19047619 | 5.3333333 | 4.75 | 5.25 | 4.50 | 21 | 0 |\n| 359 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 2 | 1 | ⋯ |  6 | 11 | 10 | 0.57142857 | 4.0000000 | 3.25 | 5.25 | 4.75 |  0 | 0 |\n| 362 | 1 | 1 | 1 | 1 | 0 | 1 | 0 | 1 | 1 | 1 | ⋯ | 10 | 35 |  6 | 0.38095238 | 2.3333333 | 2.00 | 3.00 | 2.75 |  0 | 0 |\n| 363 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ |  6 | 17 | 10 | 0.66666667 | 5.3333333 | 4.50 | 5.50 | 4.75 | 22 | 1 |\n| 365 | 1 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 2 | 1 | ⋯ |  7 |  8 |  8 | 0.19047619 | 5.0000000 | 3.00 | 5.50 | 4.00 | 23 | 1 |\n| 366 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 1 | 2 | 4 | ⋯ | 10 | 24 |  9 | 1.09523810 | 5.6666667 | 1.75 | 5.00 | 1.25 | 21 | 1 |\n| 367 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 2 | 3 | ⋯ |  0 |  3 |  6 | 0.09523809 | 0.6666667 | 0.75 | 0.50 | 0.50 | 20 | 0 |\n| 370 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 3 | 5 | ⋯ | 10 | 20 |  9 | 2.00000000 | 3.6666667 | 2.75 | 2.75 | 4.25 | 21 | 0 |\n| 375 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 0 | 2 | ⋯ |  8 | 11 |  8 | 0.85714286 | 4.6666667 | 5.00 | 5.25 | 5.00 | 22 | 0 |\n| 377 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 1 | 1 | 3 | ⋯ | 10 | 27 | 12 | 0.71428571 | 5.6666667 | 2.50 | 3.25 | 3.00 |  0 | 0 |\n| 378 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 2 | 1 | ⋯ |  7 | 42 |  9 | 1.80952381 | 4.6666667 | 1.75 | 2.00 | 3.50 |  0 | 0 |\n| 380 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 3 | 1 | ⋯ |  8 |  4 | 10 | 1.14285714 | 4.3333333 | 3.50 | 1.00 | 4.00 |  0 | 0 |\n| 381 | 0 | 1 | 1 | 0 | 0 | 0 | 1 | 1 | 3 | 4 | ⋯ |  8 |  3 | 14 | 0.04761905 | 5.6666667 | 5.50 | 5.50 | 3.75 | 21 | 0 |\n| 383 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 4 | 4 | ⋯ | 10 | 57 |  9 | 1.95238095 | 4.6666667 | 3.75 | 3.75 | 4.25 | 21 | 0 |\n| 385 | 0 | 1 | 1 | 0 | 0 | 1 | 0 | 0 | 3 | 3 | ⋯ |  9 | 39 |  8 | 0.90476190 | 5.3333333 | 5.00 | 5.00 | 4.50 |  0 | 0 |\n| 386 | 0 | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 0 | 1 | ⋯ |  8 |  3 | 11 | 0.09523809 | 5.0000000 | 2.75 | 3.50 | 4.25 |  0 | 0 |\n| 387 | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 1 | 2 | 2 | ⋯ |  8 |  4 | 13 | 0.04761905 | 5.3333333 | 5.50 | 5.50 | 5.00 | 21 | 1 |\n| 392 | 0 | 1 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | 1 | ⋯ |  6 | 21 |  9 | 0.57142857 | 4.0000000 | 4.00 | 4.50 | 3.50 | 22 | 1 |\n| 395 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | ⋯ |  0 |  0 | 10 | 0.00000000 | 5.3333333 | 5.50 | 5.50 | 3.25 | 63 | 1 |\n| 398 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 1 | 1 | 4 | ⋯ | 10 | 61 | 11 | 2.09523810 | 3.3333333 | 2.75 | 3.00 | 2.75 | 21 | 0 |\n| 399 | 0 | 1 | 0 | 1 | 0 | 0 | 1 | 1 | 0 | 0 | ⋯ |  8 | 37 |  9 | 1.28571429 | 5.6666667 | 4.25 | 5.25 | 4.75 | 19 | 0 |\n| 401 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 2 | 2 | ⋯ | 10 | 64 |  8 | 2.57142857 | 4.0000000 | 0.50 | 1.25 | 3.75 | 22 | 0 |\n| 402 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 3 | 3 | ⋯ |  7 | 34 | 11 | 0.80952381 | 1.3333333 | 2.75 | 1.50 | 2.25 |  0 | 0 |\n| 403 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ⋯ | 10 | 57 |  9 | 2.66666667 | 4.0000000 | 1.25 | 4.00 | 3.75 | 22 | 1 |\n\n",
            "text/latex": "A data.frame: 227 × 55\n\\begin{tabular}{r|lllllllllllllllllllll}\n  & gpa\\_thresh3\\_0 & role\\_family & role\\_friend & role\\_sigother & role\\_other & has\\_mother & has\\_father & stem\\_notstem & edu.r\\_count & edu.i\\_count & ⋯ & covid\\_edu & ptsd\\_score & trauma\\_sum & mh\\_scale & ss\\_friend & ss\\_family & ss\\_sigother & ss\\_community & age & first\\_gen\\\\\n  & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & ⋯ & <int> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int>\\\\\n\\hline\n\t1 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 1 & 4 & ⋯ &  6 &  0 & 13 & 0.04761905 & 5.666667 & 5.50 & 5.50 & 4.75 &  0 & 0\\\\\n\t2 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & ⋯ &  5 & 15 & 10 & 0.80952381 & 4.666667 & 5.50 & 5.50 & 4.75 & 29 & 0\\\\\n\t3 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 2 & 2 & ⋯ &  1 &  3 & 10 & 0.09523809 & 5.666667 & 5.50 & 5.50 & 5.50 & 53 & 0\\\\\n\t4 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 1 & 3 & ⋯ &  7 &  0 &  7 & 0.28571429 & 5.666667 & 5.50 & 5.50 & 5.00 & 46 & 0\\\\\n\t6 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 2 & 2 & ⋯ &  2 &  8 & 12 & 0.23809524 & 5.333333 & 3.75 & 5.50 & 4.50 &  0 & 0\\\\\n\t7 & 0 & 1 & 0 & 0 & 0 & 1 & 1 & 0 & 2 & 4 & ⋯ &  2 &  4 &  9 & 0.14285714 & 5.333333 & 4.75 & 5.50 & 5.00 & 28 & 0\\\\\n\t8 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 1 & 2 & ⋯ &  0 &  0 & 12 & 0.14285714 & 5.666667 & 5.50 & 5.50 & 3.75 & 55 & 0\\\\\n\t9 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 3 & 3 & ⋯ &  3 & 15 &  8 & 1.04761905 & 4.666667 & 5.25 & 5.50 & 5.25 &  0 & 0\\\\\n\t10 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 3 & ⋯ &  8 & 40 &  5 & 0.42857143 & 5.333333 & 4.25 & 4.50 & 3.50 &  0 & 0\\\\\n\t11 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ &  7 & 19 & 11 & 0.57142857 & 4.333333 & 5.25 & 5.50 & 4.75 & 38 & 0\\\\\n\t12 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 3 & 4 & ⋯ &  7 & 11 &  8 & 0.19047619 & 5.333333 & 4.75 & 5.50 & 5.25 & 26 & 0\\\\\n\t14 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 1 & 2 & ⋯ &  7 & 10 & 10 & 0.33333333 & 5.666667 & 2.75 & 5.50 & 5.00 & 32 & 0\\\\\n\t15 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & ⋯ & 10 & 29 &  2 & 0.80952381 & 4.333333 & 3.25 & 4.50 & 5.25 & 38 & 0\\\\\n\t17 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 1 & ⋯ &  7 &  8 & 11 & 0.33333333 & 5.666667 & 5.25 & 5.50 & 5.50 & 42 & 1\\\\\n\t18 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 5 & 6 & ⋯ &  6 & 22 & 10 & 1.00000000 & 5.000000 & 4.00 & 5.50 & 4.25 & 38 & 0\\\\\n\t24 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 1 & 4 & ⋯ &  7 & 15 & 13 & 0.52380952 & 4.333333 & 5.00 & 5.50 & 5.25 & 30 & 0\\\\\n\t27 & 1 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 2 & 2 & ⋯ & 10 & 15 &  5 & 0.66666667 & 5.666667 & 4.75 & 4.50 & 3.50 &  0 & 0\\\\\n\t29 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 5 & ⋯ &  3 & 40 &  9 & 1.09523810 & 3.333333 & 3.25 & 3.25 & 2.75 & 22 & 0\\\\\n\t30 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 2 & ⋯ &  8 & 21 & 11 & 0.52380952 & 5.666667 & 5.00 & 5.50 & 3.00 &  0 & 0\\\\\n\t33 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 1 & 4 & 4 & ⋯ &  8 & 17 &  8 & 0.23809524 & 3.666667 & 4.00 & 2.00 & 3.50 & 31 & 0\\\\\n\t36 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 4 & 4 & ⋯ &  9 & 34 & 11 & 0.85714286 & 5.666667 & 2.50 & 3.75 & 3.00 & 23 & 0\\\\\n\t37 & 0 & 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & ⋯ &  6 & 30 &  8 & 0.52380952 & 4.000000 & 5.50 & 5.00 & 3.50 &  0 & 0\\\\\n\t39 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & ⋯ &  8 & 53 &  8 & 1.47619048 & 5.666667 & 4.50 & 5.50 & 3.75 &  0 & 0\\\\\n\t45 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 2 & 4 & ⋯ &  6 & 21 & 11 & 0.76190476 & 5.666667 & 5.50 & 5.50 & 5.50 & 21 & 0\\\\\n\t46 & 0 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 2 & 2 & ⋯ &  5 & 64 &  7 & 2.57142857 & 1.666667 & 2.25 & 3.50 & 3.00 & 19 & 0\\\\\n\t47 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & ⋯ &  7 & 34 &  8 & 0.95238095 & 5.000000 & 4.00 & 5.25 & 4.25 & 20 & 0\\\\\n\t49 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 1 & 0 & 3 & ⋯ & 10 & 24 & 11 & 0.61904762 & 5.666667 & 5.50 & 5.25 & 4.00 & 32 & 0\\\\\n\t50 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 1 & 2 & ⋯ &  6 &  9 & 14 & 0.66666667 & 5.333333 & 4.00 & 5.50 & 5.25 &  0 & 0\\\\\n\t52 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 2 & 2 & ⋯ &  3 & 48 &  8 & 0.66666667 & 5.333333 & 3.75 & 4.00 & 5.50 & 20 & 0\\\\\n\t53 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 1 & 1 & 1 & ⋯ &  3 & 10 & 11 & 0.61904762 & 5.666667 & 5.25 & 5.50 & 4.00 & 29 & 1\\\\\n\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n\t347 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 & 1 & 1 & ⋯ &  8 & 12 & 10 & 0.71428571 & 5.3333333 & 5.25 & 5.50 & 4.50 & 22 & 1\\\\\n\t350 & 1 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 2 & 2 & ⋯ &  9 &  0 & 10 & 0.19047619 & 4.6666667 & 4.25 & 5.50 & 5.00 & 24 & 0\\\\\n\t354 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 2 & 2 & ⋯ &  7 & 26 &  5 & 1.23809524 & 5.3333333 & 3.25 & 4.25 & 5.25 & 21 & 0\\\\\n\t355 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & ⋯ & 10 & 34 & 10 & 1.04761905 & 5.6666667 & 1.50 & 5.50 & 5.25 &  0 & 0\\\\\n\t356 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 1 & 1 & ⋯ &  6 &  1 & 10 & 0.09523809 & 5.6666667 & 5.25 & 5.50 & 5.50 & 23 & 0\\\\\n\t357 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & ⋯ &  7 & 26 & 11 & 0.52380952 & 4.0000000 & 3.50 & 3.00 & 3.50 &  0 & 0\\\\\n\t358 & 1 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 1 & 3 & ⋯ &  7 & 15 & 10 & 0.19047619 & 5.3333333 & 4.75 & 5.25 & 4.50 & 21 & 0\\\\\n\t359 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 2 & 1 & ⋯ &  6 & 11 & 10 & 0.57142857 & 4.0000000 & 3.25 & 5.25 & 4.75 &  0 & 0\\\\\n\t362 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 1 & ⋯ & 10 & 35 &  6 & 0.38095238 & 2.3333333 & 2.00 & 3.00 & 2.75 &  0 & 0\\\\\n\t363 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ &  6 & 17 & 10 & 0.66666667 & 5.3333333 & 4.50 & 5.50 & 4.75 & 22 & 1\\\\\n\t365 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 2 & 1 & ⋯ &  7 &  8 &  8 & 0.19047619 & 5.0000000 & 3.00 & 5.50 & 4.00 & 23 & 1\\\\\n\t366 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 2 & 4 & ⋯ & 10 & 24 &  9 & 1.09523810 & 5.6666667 & 1.75 & 5.00 & 1.25 & 21 & 1\\\\\n\t367 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 2 & 3 & ⋯ &  0 &  3 &  6 & 0.09523809 & 0.6666667 & 0.75 & 0.50 & 0.50 & 20 & 0\\\\\n\t370 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 3 & 5 & ⋯ & 10 & 20 &  9 & 2.00000000 & 3.6666667 & 2.75 & 2.75 & 4.25 & 21 & 0\\\\\n\t375 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 0 & 2 & ⋯ &  8 & 11 &  8 & 0.85714286 & 4.6666667 & 5.00 & 5.25 & 5.00 & 22 & 0\\\\\n\t377 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 1 & 3 & ⋯ & 10 & 27 & 12 & 0.71428571 & 5.6666667 & 2.50 & 3.25 & 3.00 &  0 & 0\\\\\n\t378 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 2 & 1 & ⋯ &  7 & 42 &  9 & 1.80952381 & 4.6666667 & 1.75 & 2.00 & 3.50 &  0 & 0\\\\\n\t380 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 3 & 1 & ⋯ &  8 &  4 & 10 & 1.14285714 & 4.3333333 & 3.50 & 1.00 & 4.00 &  0 & 0\\\\\n\t381 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 1 & 3 & 4 & ⋯ &  8 &  3 & 14 & 0.04761905 & 5.6666667 & 5.50 & 5.50 & 3.75 & 21 & 0\\\\\n\t383 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 4 & 4 & ⋯ & 10 & 57 &  9 & 1.95238095 & 4.6666667 & 3.75 & 3.75 & 4.25 & 21 & 0\\\\\n\t385 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 3 & 3 & ⋯ &  9 & 39 &  8 & 0.90476190 & 5.3333333 & 5.00 & 5.00 & 4.50 &  0 & 0\\\\\n\t386 & 0 & 1 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 1 & ⋯ &  8 &  3 & 11 & 0.09523809 & 5.0000000 & 2.75 & 3.50 & 4.25 &  0 & 0\\\\\n\t387 & 1 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 2 & 2 & ⋯ &  8 &  4 & 13 & 0.04761905 & 5.3333333 & 5.50 & 5.50 & 5.00 & 21 & 1\\\\\n\t392 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & ⋯ &  6 & 21 &  9 & 0.57142857 & 4.0000000 & 4.00 & 4.50 & 3.50 & 22 & 1\\\\\n\t395 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 1 & ⋯ &  0 &  0 & 10 & 0.00000000 & 5.3333333 & 5.50 & 5.50 & 3.25 & 63 & 1\\\\\n\t398 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 4 & ⋯ & 10 & 61 & 11 & 2.09523810 & 3.3333333 & 2.75 & 3.00 & 2.75 & 21 & 0\\\\\n\t399 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & ⋯ &  8 & 37 &  9 & 1.28571429 & 5.6666667 & 4.25 & 5.25 & 4.75 & 19 & 0\\\\\n\t401 & 0 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 2 & 2 & ⋯ & 10 & 64 &  8 & 2.57142857 & 4.0000000 & 0.50 & 1.25 & 3.75 & 22 & 0\\\\\n\t402 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 3 & 3 & ⋯ &  7 & 34 & 11 & 0.80952381 & 1.3333333 & 2.75 & 1.50 & 2.25 &  0 & 0\\\\\n\t403 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ⋯ & 10 & 57 &  9 & 2.66666667 & 4.0000000 & 1.25 & 4.00 & 3.75 & 22 & 1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "    gpa_thresh3_0 role_family role_friend role_sigother role_other has_mother\n",
              "1   0             1           1           1             0          1         \n",
              "2   0             1           0           1             0          1         \n",
              "3   0             1           1           1             0          1         \n",
              "4   0             1           1           1             0          1         \n",
              "6   0             1           1           0             0          1         \n",
              "7   0             1           0           0             0          1         \n",
              "8   0             1           1           1             0          1         \n",
              "9   0             1           1           1             0          1         \n",
              "10  0             1           0           1             0          1         \n",
              "11  0             0           1           1             0          0         \n",
              "12  0             0           1           1             0          0         \n",
              "14  0             1           1           1             0          1         \n",
              "15  0             1           1           1             0          1         \n",
              "17  0             1           1           1             0          1         \n",
              "18  0             1           1           1             0          0         \n",
              "24  1             1           1           1             0          0         \n",
              "27  1             1           1           0             0          1         \n",
              "29  1             1           1           1             0          1         \n",
              "30  0             1           1           1             0          0         \n",
              "33  1             1           1           1             0          1         \n",
              "36  0             1           1           0             0          1         \n",
              "37  0             1           0           0             0          1         \n",
              "39  1             1           0           1             0          0         \n",
              "45  0             1           1           0             0          1         \n",
              "46  0             1           0           1             0          1         \n",
              "47  0             1           1           1             0          1         \n",
              "49  0             1           1           1             0          1         \n",
              "50  0             1           1           0             0          1         \n",
              "52  0             1           1           0             0          0         \n",
              "53  1             1           1           0             1          0         \n",
              "⋮   ⋮             ⋮           ⋮           ⋮             ⋮          ⋮         \n",
              "347 0             1           1           0             0          1         \n",
              "350 1             1           1           1             0          1         \n",
              "354 0             1           0           0             0          0         \n",
              "355 1             1           0           1             0          1         \n",
              "356 1             1           1           1             0          1         \n",
              "357 1             1           1           0             0          0         \n",
              "358 1             1           1           1             0          1         \n",
              "359 0             0           1           1             1          0         \n",
              "362 1             1           1           1             0          1         \n",
              "363 0             1           1           0             0          0         \n",
              "365 1             1           0           0             0          1         \n",
              "366 0             1           1           0             0          0         \n",
              "367 1             1           1           0             0          0         \n",
              "370 1             1           1           1             0          0         \n",
              "375 0             1           1           0             0          1         \n",
              "377 0             0           1           1             0          0         \n",
              "378 0             1           1           0             0          1         \n",
              "380 0             1           1           0             0          1         \n",
              "381 0             1           1           0             0          0         \n",
              "383 0             1           1           0             0          1         \n",
              "385 0             1           1           0             0          1         \n",
              "386 0             1           0           0             0          1         \n",
              "387 1             1           1           1             0          1         \n",
              "392 0             1           1           1             0          1         \n",
              "395 0             1           1           1             0          1         \n",
              "398 0             1           1           1             0          1         \n",
              "399 0             1           0           1             0          0         \n",
              "401 0             1           1           0             0          1         \n",
              "402 0             0           1           0             0          0         \n",
              "403 0             1           1           0             0          0         \n",
              "    has_father stem_notstem edu.r_count edu.i_count ⋯ covid_edu ptsd_score\n",
              "1   1          0            1           4           ⋯  6         0        \n",
              "2   0          0            0           0           ⋯  5        15        \n",
              "3   1          0            2           2           ⋯  1         3        \n",
              "4   1          0            1           3           ⋯  7         0        \n",
              "6   0          0            2           2           ⋯  2         8        \n",
              "7   1          0            2           4           ⋯  2         4        \n",
              "8   0          0            1           2           ⋯  0         0        \n",
              "9   1          0            3           3           ⋯  3        15        \n",
              "10  0          0            0           3           ⋯  8        40        \n",
              "11  0          0            0           0           ⋯  7        19        \n",
              "12  0          0            3           4           ⋯  7        11        \n",
              "14  0          0            1           2           ⋯  7        10        \n",
              "15  1          0            1           1           ⋯ 10        29        \n",
              "17  1          0            0           1           ⋯  7         8        \n",
              "18  0          0            5           6           ⋯  6        22        \n",
              "24  0          1            1           4           ⋯  7        15        \n",
              "27  1          1            2           2           ⋯ 10        15        \n",
              "29  0          1            1           5           ⋯  3        40        \n",
              "30  0          0            0           2           ⋯  8        21        \n",
              "33  0          1            4           4           ⋯  8        17        \n",
              "36  1          1            4           4           ⋯  9        34        \n",
              "37  1          0            0           0           ⋯  6        30        \n",
              "39  0          0            1           1           ⋯  8        53        \n",
              "45  1          1            2           4           ⋯  6        21        \n",
              "46  1          0            2           2           ⋯  5        64        \n",
              "47  1          1            0           1           ⋯  7        34        \n",
              "49  0          1            0           3           ⋯ 10        24        \n",
              "50  1          1            1           2           ⋯  6         9        \n",
              "52  0          0            2           2           ⋯  3        48        \n",
              "53  0          1            1           1           ⋯  3        10        \n",
              "⋮   ⋮          ⋮            ⋮           ⋮           ⋱ ⋮         ⋮         \n",
              "347 0          1            1           1           ⋯  8        12        \n",
              "350 1          0            2           2           ⋯  9         0        \n",
              "354 1          0            2           2           ⋯  7        26        \n",
              "355 1          0            0           0           ⋯ 10        34        \n",
              "356 0          0            1           1           ⋯  6         1        \n",
              "357 0          0            1           1           ⋯  7        26        \n",
              "358 1          0            1           3           ⋯  7        15        \n",
              "359 0          0            2           1           ⋯  6        11        \n",
              "362 0          1            1           1           ⋯ 10        35        \n",
              "363 0          0            0           0           ⋯  6        17        \n",
              "365 0          0            2           1           ⋯  7         8        \n",
              "366 0          1            2           4           ⋯ 10        24        \n",
              "367 0          0            2           3           ⋯  0         3        \n",
              "370 0          0            3           5           ⋯ 10        20        \n",
              "375 1          1            0           2           ⋯  8        11        \n",
              "377 0          1            1           3           ⋯ 10        27        \n",
              "378 1          1            2           1           ⋯  7        42        \n",
              "380 1          1            3           1           ⋯  8         4        \n",
              "381 1          1            3           4           ⋯  8         3        \n",
              "383 1          1            4           4           ⋯ 10        57        \n",
              "385 0          0            3           3           ⋯  9        39        \n",
              "386 1          1            0           1           ⋯  8         3        \n",
              "387 1          1            2           2           ⋯  8         4        \n",
              "392 0          0            0           1           ⋯  6        21        \n",
              "395 1          0            0           1           ⋯  0         0        \n",
              "398 1          1            1           4           ⋯ 10        61        \n",
              "399 1          1            0           0           ⋯  8        37        \n",
              "401 1          1            2           2           ⋯ 10        64        \n",
              "402 0          1            3           3           ⋯  7        34        \n",
              "403 0          0            0           0           ⋯ 10        57        \n",
              "    trauma_sum mh_scale   ss_friend ss_family ss_sigother ss_community age\n",
              "1   13         0.04761905 5.666667  5.50      5.50        4.75          0 \n",
              "2   10         0.80952381 4.666667  5.50      5.50        4.75         29 \n",
              "3   10         0.09523809 5.666667  5.50      5.50        5.50         53 \n",
              "4    7         0.28571429 5.666667  5.50      5.50        5.00         46 \n",
              "6   12         0.23809524 5.333333  3.75      5.50        4.50          0 \n",
              "7    9         0.14285714 5.333333  4.75      5.50        5.00         28 \n",
              "8   12         0.14285714 5.666667  5.50      5.50        3.75         55 \n",
              "9    8         1.04761905 4.666667  5.25      5.50        5.25          0 \n",
              "10   5         0.42857143 5.333333  4.25      4.50        3.50          0 \n",
              "11  11         0.57142857 4.333333  5.25      5.50        4.75         38 \n",
              "12   8         0.19047619 5.333333  4.75      5.50        5.25         26 \n",
              "14  10         0.33333333 5.666667  2.75      5.50        5.00         32 \n",
              "15   2         0.80952381 4.333333  3.25      4.50        5.25         38 \n",
              "17  11         0.33333333 5.666667  5.25      5.50        5.50         42 \n",
              "18  10         1.00000000 5.000000  4.00      5.50        4.25         38 \n",
              "24  13         0.52380952 4.333333  5.00      5.50        5.25         30 \n",
              "27   5         0.66666667 5.666667  4.75      4.50        3.50          0 \n",
              "29   9         1.09523810 3.333333  3.25      3.25        2.75         22 \n",
              "30  11         0.52380952 5.666667  5.00      5.50        3.00          0 \n",
              "33   8         0.23809524 3.666667  4.00      2.00        3.50         31 \n",
              "36  11         0.85714286 5.666667  2.50      3.75        3.00         23 \n",
              "37   8         0.52380952 4.000000  5.50      5.00        3.50          0 \n",
              "39   8         1.47619048 5.666667  4.50      5.50        3.75          0 \n",
              "45  11         0.76190476 5.666667  5.50      5.50        5.50         21 \n",
              "46   7         2.57142857 1.666667  2.25      3.50        3.00         19 \n",
              "47   8         0.95238095 5.000000  4.00      5.25        4.25         20 \n",
              "49  11         0.61904762 5.666667  5.50      5.25        4.00         32 \n",
              "50  14         0.66666667 5.333333  4.00      5.50        5.25          0 \n",
              "52   8         0.66666667 5.333333  3.75      4.00        5.50         20 \n",
              "53  11         0.61904762 5.666667  5.25      5.50        4.00         29 \n",
              "⋮   ⋮          ⋮          ⋮         ⋮         ⋮           ⋮            ⋮  \n",
              "347 10         0.71428571 5.3333333 5.25      5.50        4.50         22 \n",
              "350 10         0.19047619 4.6666667 4.25      5.50        5.00         24 \n",
              "354  5         1.23809524 5.3333333 3.25      4.25        5.25         21 \n",
              "355 10         1.04761905 5.6666667 1.50      5.50        5.25          0 \n",
              "356 10         0.09523809 5.6666667 5.25      5.50        5.50         23 \n",
              "357 11         0.52380952 4.0000000 3.50      3.00        3.50          0 \n",
              "358 10         0.19047619 5.3333333 4.75      5.25        4.50         21 \n",
              "359 10         0.57142857 4.0000000 3.25      5.25        4.75          0 \n",
              "362  6         0.38095238 2.3333333 2.00      3.00        2.75          0 \n",
              "363 10         0.66666667 5.3333333 4.50      5.50        4.75         22 \n",
              "365  8         0.19047619 5.0000000 3.00      5.50        4.00         23 \n",
              "366  9         1.09523810 5.6666667 1.75      5.00        1.25         21 \n",
              "367  6         0.09523809 0.6666667 0.75      0.50        0.50         20 \n",
              "370  9         2.00000000 3.6666667 2.75      2.75        4.25         21 \n",
              "375  8         0.85714286 4.6666667 5.00      5.25        5.00         22 \n",
              "377 12         0.71428571 5.6666667 2.50      3.25        3.00          0 \n",
              "378  9         1.80952381 4.6666667 1.75      2.00        3.50          0 \n",
              "380 10         1.14285714 4.3333333 3.50      1.00        4.00          0 \n",
              "381 14         0.04761905 5.6666667 5.50      5.50        3.75         21 \n",
              "383  9         1.95238095 4.6666667 3.75      3.75        4.25         21 \n",
              "385  8         0.90476190 5.3333333 5.00      5.00        4.50          0 \n",
              "386 11         0.09523809 5.0000000 2.75      3.50        4.25          0 \n",
              "387 13         0.04761905 5.3333333 5.50      5.50        5.00         21 \n",
              "392  9         0.57142857 4.0000000 4.00      4.50        3.50         22 \n",
              "395 10         0.00000000 5.3333333 5.50      5.50        3.25         63 \n",
              "398 11         2.09523810 3.3333333 2.75      3.00        2.75         21 \n",
              "399  9         1.28571429 5.6666667 4.25      5.25        4.75         19 \n",
              "401  8         2.57142857 4.0000000 0.50      1.25        3.75         22 \n",
              "402 11         0.80952381 1.3333333 2.75      1.50        2.25          0 \n",
              "403  9         2.66666667 4.0000000 1.25      4.00        3.75         22 \n",
              "    first_gen\n",
              "1   0        \n",
              "2   0        \n",
              "3   0        \n",
              "4   0        \n",
              "6   0        \n",
              "7   0        \n",
              "8   0        \n",
              "9   0        \n",
              "10  0        \n",
              "11  0        \n",
              "12  0        \n",
              "14  0        \n",
              "15  0        \n",
              "17  1        \n",
              "18  0        \n",
              "24  0        \n",
              "27  0        \n",
              "29  0        \n",
              "30  0        \n",
              "33  0        \n",
              "36  0        \n",
              "37  0        \n",
              "39  0        \n",
              "45  0        \n",
              "46  0        \n",
              "47  0        \n",
              "49  0        \n",
              "50  0        \n",
              "52  0        \n",
              "53  1        \n",
              "⋮   ⋮        \n",
              "347 1        \n",
              "350 0        \n",
              "354 0        \n",
              "355 0        \n",
              "356 0        \n",
              "357 0        \n",
              "358 0        \n",
              "359 0        \n",
              "362 0        \n",
              "363 1        \n",
              "365 1        \n",
              "366 1        \n",
              "367 0        \n",
              "370 0        \n",
              "375 0        \n",
              "377 0        \n",
              "378 0        \n",
              "380 0        \n",
              "381 0        \n",
              "383 0        \n",
              "385 0        \n",
              "386 0        \n",
              "387 1        \n",
              "392 1        \n",
              "395 1        \n",
              "398 0        \n",
              "399 0        \n",
              "401 0        \n",
              "402 0        \n",
              "403 1        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")"
      ],
      "metadata": {
        "id": "_bcLpp71PBkm"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyYMQB94PDxf",
        "outputId": "d9aa3dc5-569a-45ff-fe05-8df86358695d"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.120536\ttest-error:1.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.040179\ttest-error:1.000000 \n",
            "[21]\ttrain-error:0.026786\ttest-error:1.000000 \n",
            "[31]\ttrain-error:0.008929\ttest-error:1.000000 \n",
            "[41]\ttrain-error:0.004464\ttest-error:1.000000 \n",
            "[51]\ttrain-error:0.004464\ttest-error:1.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.120536\ttest-error:1.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred <- predict(fit_xgb, train.intake)"
      ],
      "metadata": {
        "id": "RhrbJoWCPGSs"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "dif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Pf7GWR6vPIZF",
        "outputId": "4be92949-86bc-4f1d-db35-711cb30a825f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "3"
            ],
            "text/markdown": "3",
            "text/latex": "3",
            "text/plain": [
              "[1] 3"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}"
      ],
      "metadata": {
        "id": "mzGBl0SoPJ91"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))"
      ],
      "metadata": {
        "id": "kUnruVr5SHC6"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)"
      ],
      "metadata": {
        "id": "hFWHV5LOPLkN"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "HFzjptcuPO1V",
        "outputId": "631bf718-48c7-42c1-8424-4d8cd9071bd5"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)     0.8323    0.04594  18.120 7.461e-46   0.7418  0.92287 225\n",
              "gpa_thresh3_0  -0.1896    0.08903  -2.129 3.433e-02  -0.3650 -0.01412 225\n",
              "\n",
              "Multiple R-squared:  0.01854 ,\tAdjusted R-squared:  0.01418 \n",
              "F-statistic: 4.533 on 1 and 225 DF,  p-value: 0.03433"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using PTSD score as primary predictor"
      ],
      "metadata": {
        "id": "fB_8vzQSLlqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('gender_female.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "id": "FN5QBtbEAghJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "37f145c6-4bc8-4917-c57c-d985961add36"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.071429\ttest-error:0.666667 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.053571\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.044643\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.022321\ttest-error:0.333333 \n",
            "[41]\ttrain-error:0.013393\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.004464\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.004464\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[5]\ttrain-error:0.049107\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)   0.5297    0.03231   16.39 2.875e-40    0.466   0.5934 225\n",
              "ptsd_score    0.8487    0.07343   11.56 1.457e-24    0.704   0.9934 225\n",
              "\n",
              "Multiple R-squared:  0.4369 ,\tAdjusted R-squared:  0.4344 \n",
              "F-statistic: 133.6 on 1 and 225 DF,  p-value: < 2.2e-16"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using age as primary predictor"
      ],
      "metadata": {
        "id": "4ZmVNYsaMbMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "median(data.intake$age)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3oLIZmdXMqko",
        "outputId": "66ec2eac-1ef2-413d-c222-96e14870b2a5"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "20"
            ],
            "text/markdown": "20",
            "text/latex": "20",
            "text/plain": [
              "[1] 20"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('gender_female.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(age = ifelse(age < 21, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"age\" %in% col_names){\n",
        "  new_col_order <- c(\"age\", col_names[col_names != \"age\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$age==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ age, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "9EJqJjqTMCrf",
        "outputId": "28dbe0d6-91b5-4788-c6d6-35eb12a715e6"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.165179\ttest-error:0.666667 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.031250\ttest-error:0.333333 \n",
            "[21]\ttrain-error:0.004464\ttest-error:0.333333 \n",
            "[31]\ttrain-error:0.000000\ttest-error:0.333333 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.666667 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.666667 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.666667 \n",
            "[71]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "Stopping. Best iteration:\n",
            "[4]\ttrain-error:0.120536\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ age, data = data.intake, weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)  0.81154    0.06053 13.4078 1.618e-30   0.6923   0.9308 225\n",
              "age         -0.03458    0.08107 -0.4265 6.701e-01  -0.1943   0.1252 225\n",
              "\n",
              "Multiple R-squared:  0.0008267 ,\tAdjusted R-squared:  -0.003614 \n",
              "F-statistic: 0.1819 on 1 and 225 DF,  p-value: 0.6701"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using edu.i_count as predidctor"
      ],
      "metadata": {
        "id": "isvM1WhcOrH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('gender_female.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(edu.i_count = ifelse(edu.i_count <= 2, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"edu.i_count\" %in% col_names){\n",
        "  new_col_order <- c(\"edu.i_count\", col_names[col_names != \"edu.i_count\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$edu.i_count==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ edu.i_count, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "nEy6bo2bNiB1",
        "outputId": "7ccd4161-6c37-448c-d991-209b3a79b436"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.075893\ttest-error:0.333333 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.044643\ttest-error:0.333333 \n",
            "[21]\ttrain-error:0.031250\ttest-error:0.333333 \n",
            "[31]\ttrain-error:0.022321\ttest-error:0.333333 \n",
            "[41]\ttrain-error:0.013393\ttest-error:0.333333 \n",
            "[51]\ttrain-error:0.004464\ttest-error:0.333333 \n",
            "[61]\ttrain-error:0.004464\ttest-error:0.333333 \n",
            "[71]\ttrain-error:0.004464\ttest-error:0.333333 \n",
            "[81]\ttrain-error:0.004464\ttest-error:0.333333 \n",
            "[91]\ttrain-error:0.004464\ttest-error:0.333333 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.333333 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.075893\ttest-error:0.333333\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ edu.i_count, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)   0.7062    0.05987  11.796 2.558e-25  0.58825   0.8242 225\n",
              "edu.i_count   0.1270    0.07917   1.604 1.102e-01 -0.02906   0.2830 225\n",
              "\n",
              "Multiple R-squared:  0.01061 ,\tAdjusted R-squared:  0.006208 \n",
              "F-statistic: 2.571 on 1 and 225 DF,  p-value: 0.1102"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cisgender Man Subgroup"
      ],
      "metadata": {
        "id": "mUDob-i_cthR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA as primary predictor"
      ],
      "metadata": {
        "id": "tm5y1a-vcwpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('gender_male.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "n90zGO7EOabH",
        "outputId": "94ec1194-2a0a-4e6e-c6b3-d7de96fdaa98"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.188679\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.094340\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.075472\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.037736\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.188679\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)    0.77227     0.1021   7.560 6.339e-10   0.5673   0.9772 52\n",
              "gpa_thresh3_0  0.07611     0.2213   0.344 7.323e-01  -0.3679   0.5201 52\n",
              "\n",
              "Multiple R-squared:  0.002269 ,\tAdjusted R-squared:  -0.01692 \n",
              "F-statistic: 0.1183 on 1 and 52 DF,  p-value: 0.7323"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTSD"
      ],
      "metadata": {
        "id": "845l-QyQeIz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('gender_male.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "Dhvgph6YdHhS",
        "outputId": "bb90a79c-8560-41aa-d36c-48ee6185717c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.075472\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.056604\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.056604\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.056604\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.056604\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.037736\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.037736\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.075472\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.4615    0.05696   8.103 8.746e-11   0.3472   0.5758 52\n",
              "ptsd_score    1.1782    0.13625   8.647 1.225e-11   0.9048   1.4516 52\n",
              "\n",
              "Multiple R-squared:  0.6542 ,\tAdjusted R-squared:  0.6476 \n",
              "F-statistic: 74.78 on 1 and 52 DF,  p-value: 1.225e-11"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age"
      ],
      "metadata": {
        "id": "h_o70LxxeV3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('gender_male.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(age = ifelse(age < 21, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"age\" %in% col_names){\n",
        "  new_col_order <- c(\"age\", col_names[col_names != \"age\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$age==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ age, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "__xvZayDeKxK",
        "outputId": "dc42bcb4-c99c-40d4-8dab-5efc644d1a14"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.188679\ttest-error:1.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.037736\ttest-error:1.000000 \n",
            "[21]\ttrain-error:0.018868\ttest-error:1.000000 \n",
            "[31]\ttrain-error:0.018868\ttest-error:1.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[51]\ttrain-error:0.018868\ttest-error:1.000000 \n",
            "[61]\ttrain-error:0.018868\ttest-error:1.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[111]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[121]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[131]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[141]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[151]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[161]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[171]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[181]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[191]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[99]\ttrain-error:0.000000\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ age, data = data.intake, weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.8468     0.2194  3.8597 0.0003154   0.4065   1.2870 52\n",
              "age          -0.0899     0.2610 -0.3445 0.7318755  -0.6136   0.4338 52\n",
              "\n",
              "Multiple R-squared:  0.004607 ,\tAdjusted R-squared:  -0.01454 \n",
              "F-statistic: 0.1187 on 1 and 52 DF,  p-value: 0.7319"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('gender_male.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(edu.i_count = ifelse(edu.i_count <= 2, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"edu.i_count\" %in% col_names){\n",
        "  new_col_order <- c(\"edu.i_count\", col_names[col_names != \"edu.i_count\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$edu.i_count==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ edu.i_count, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "yQUEQX3veXiR",
        "outputId": "8ed67444-df24-471f-e85d-14a0fb8bd586"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.113208\ttest-error:1.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.056604\ttest-error:1.000000 \n",
            "[21]\ttrain-error:0.037736\ttest-error:1.000000 \n",
            "[31]\ttrain-error:0.018868\ttest-error:1.000000 \n",
            "[41]\ttrain-error:0.018868\ttest-error:1.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.113208\ttest-error:1.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ edu.i_count, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.5402     0.1106   4.883 1.035e-05  0.31820   0.7622 52\n",
              "edu.i_count   0.3989     0.1652   2.414 1.932e-02  0.06735   0.7305 52\n",
              "\n",
              "Multiple R-squared:  0.08883 ,\tAdjusted R-squared:  0.0713 \n",
              "F-statistic: 5.829 on 1 and 52 DF,  p-value: 0.01932"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 18-20 subgroup"
      ],
      "metadata": {
        "id": "EZOLCt5XhaQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA"
      ],
      "metadata": {
        "id": "kCCxc0bjhcW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages18_20.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "l8vX63Yzej6N",
        "outputId": "9eb871a8-2290-4e53-df92-75cbcf215d81"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.072727\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.090909\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.072727\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.072727\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.054545\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.036364\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.036364\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.036364\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.018182\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.018182\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.018182\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.072727\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)     0.8894    0.09546   9.317 7.854e-13   0.6980   1.0808 54\n",
              "gpa_thresh3_0  -0.2728    0.24928  -1.095 2.786e-01  -0.7726   0.2269 54\n",
              "\n",
              "Multiple R-squared:  0.02219 ,\tAdjusted R-squared:  0.004079 \n",
              "F-statistic: 1.198 on 1 and 54 DF,  p-value: 0.2786"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTSD"
      ],
      "metadata": {
        "id": "8W-kMDIkhu3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages18_20.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "KgUjy9FWhoQf",
        "outputId": "1d360019-3096-4841-c34e-52134a74a9b6"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.127273\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.090909\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.072727\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.054545\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.018182\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.127273\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.4649    0.06553   7.095 2.886e-09   0.3335   0.5963 54\n",
              "ptsd_score    0.9857    0.13515   7.294 1.373e-09   0.7148   1.2567 54\n",
              "\n",
              "Multiple R-squared:  0.5403 ,\tAdjusted R-squared:  0.5318 \n",
              "F-statistic:  53.2 on 1 and 54 DF,  p-value: 1.373e-09"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max.emohelp"
      ],
      "metadata": {
        "id": "bcfkIsElh2pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(data.intake$max.emohelp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "NUh5DI3Fh9zD",
        "outputId": "541ab297-dbd4-44e4-a2f9-8286ccc2f67a"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>9</li><li>10</li><li>7</li><li>8</li><li>8</li><li>10</li><li>10</li><li>9</li><li>10</li><li>9</li><li>8</li><li>10</li><li>10</li><li>10</li><li>9</li><li>9</li><li>10</li><li>9</li><li>7</li><li>10</li><li>8</li><li>5</li><li>10</li><li>10</li><li>9</li><li>9</li><li>10</li><li>10</li><li>7</li><li>10</li><li>10</li><li>9</li><li>10</li><li>8</li><li>10</li><li>5</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>8</li><li>9</li><li>10</li><li>9</li><li>9</li><li>9</li><li>10</li><li>7</li><li>10</li><li>10</li><li>0</li><li>10</li><li>10</li><li>8</li><li>0</li></ol>\n"
            ],
            "text/markdown": "1. 9\n2. 10\n3. 7\n4. 8\n5. 8\n6. 10\n7. 10\n8. 9\n9. 10\n10. 9\n11. 8\n12. 10\n13. 10\n14. 10\n15. 9\n16. 9\n17. 10\n18. 9\n19. 7\n20. 10\n21. 8\n22. 5\n23. 10\n24. 10\n25. 9\n26. 9\n27. 10\n28. 10\n29. 7\n30. 10\n31. 10\n32. 9\n33. 10\n34. 8\n35. 10\n36. 5\n37. 10\n38. 10\n39. 10\n40. 10\n41. 10\n42. 8\n43. 9\n44. 10\n45. 9\n46. 9\n47. 9\n48. 10\n49. 7\n50. 10\n51. 10\n52. 0\n53. 10\n54. 10\n55. 8\n56. 0\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 9\n\\item 10\n\\item 7\n\\item 8\n\\item 8\n\\item 10\n\\item 10\n\\item 9\n\\item 10\n\\item 9\n\\item 8\n\\item 10\n\\item 10\n\\item 10\n\\item 9\n\\item 9\n\\item 10\n\\item 9\n\\item 7\n\\item 10\n\\item 8\n\\item 5\n\\item 10\n\\item 10\n\\item 9\n\\item 9\n\\item 10\n\\item 10\n\\item 7\n\\item 10\n\\item 10\n\\item 9\n\\item 10\n\\item 8\n\\item 10\n\\item 5\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 8\n\\item 9\n\\item 10\n\\item 9\n\\item 9\n\\item 9\n\\item 10\n\\item 7\n\\item 10\n\\item 10\n\\item 0\n\\item 10\n\\item 10\n\\item 8\n\\item 0\n\\end{enumerate*}\n",
            "text/plain": [
              " [1]  9 10  7  8  8 10 10  9 10  9  8 10 10 10  9  9 10  9  7 10  8  5 10 10  9\n",
              "[26]  9 10 10  7 10 10  9 10  8 10  5 10 10 10 10 10  8  9 10  9  9  9 10  7 10\n",
              "[51] 10  0 10 10  8  0"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages18_20.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(max.emohelp = ifelse(max.emohelp >= 9, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"max.emohelp\" %in% col_names){\n",
        "  new_col_order <- c(\"max.emohelp\", col_names[col_names != \"max.emohelp\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$max.emohelp==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ max.emohelp, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "-RC9aU3uhxm6",
        "outputId": "b096587c-eaed-4bd7-844f-4140b1b9ec11"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.036364\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.036364\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.036364\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.036364\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.036364\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ max.emohelp, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   1.0020     0.1637   6.120 1.095e-07   0.6737   1.3303 54\n",
              "max.emohelp  -0.2014     0.1950  -1.033 3.064e-01  -0.5924   0.1896 54\n",
              "\n",
              "Multiple R-squared:  0.01882 ,\tAdjusted R-squared:  0.0006496 \n",
              "F-statistic: 1.066 on 1 and 54 DF,  p-value: 0.3064"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ages 21-24"
      ],
      "metadata": {
        "id": "AunBP0OLjUye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA"
      ],
      "metadata": {
        "id": "ODb8dmnFjWoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages21_24.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "pfnL7BfgjSAr",
        "outputId": "7891702e-4673-49cf-e1a4-66ecdb9f2fb9"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.208791\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.043956\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.032967\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.208791\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)     0.9550    0.08725  10.946 3.169e-18   0.7816   1.1283 90\n",
              "gpa_thresh3_0  -0.3766    0.12949  -2.909 4.571e-03  -0.6339  -0.1194 90\n",
              "\n",
              "Multiple R-squared:  0.07475 ,\tAdjusted R-squared:  0.06447 \n",
              "F-statistic: 8.461 on 1 and 90 DF,  p-value: 0.004571"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ptsd"
      ],
      "metadata": {
        "id": "r1kiUeC_j054"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages21_24.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "CDT_d14rjSAt",
        "outputId": "3caffd63-c975-4ac1-deec-c0e12ad15dd4"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.109890\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.065934\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.032967\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.109890\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)    0.485    0.05096   9.517 2.883e-15   0.3838   0.5863 90\n",
              "ptsd_score     1.028    0.10830   9.488 3.324e-15   0.8124   1.2427 90\n",
              "\n",
              "Multiple R-squared:  0.5498 ,\tAdjusted R-squared:  0.5448 \n",
              "F-statistic: 90.01 on 1 and 90 DF,  p-value: 3.324e-15"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "max.emohelp"
      ],
      "metadata": {
        "id": "dWBEbgy1jymx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(data.intake$max.emohelp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "55b65ab8-9318-420e-b282-be9cc607607f",
        "id": "085fCLWejSAt"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>10</li><li>7</li><li>8</li><li>10</li><li>9</li><li>10</li><li>8</li><li>10</li><li>9</li><li>10</li><li>9</li><li>9</li><li>0</li><li>8</li><li>10</li><li>9</li><li>8</li><li>10</li><li>9</li><li>8</li><li>9</li><li>10</li><li>8</li><li>8</li><li>10</li><li>10</li><li>8</li><li>10</li><li>10</li><li>7</li><li>10</li><li>9</li><li>7</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>8</li><li>10</li><li>10</li><li>8</li><li>10</li><li>10</li><li>8</li><li>10</li><li>10</li><li>9</li><li>7</li><li>10</li><li>8</li><li>10</li><li>8</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>9</li><li>0</li><li>9</li><li>5</li><li>8</li><li>10</li><li>9</li><li>7</li><li>10</li><li>8</li><li>0</li><li>10</li><li>10</li><li>10</li><li>8</li><li>10</li><li>10</li><li>7</li><li>10</li><li>10</li><li>10</li><li>5</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>9</li><li>10</li><li>9</li></ol>\n"
            ],
            "text/markdown": "1. 10\n2. 7\n3. 8\n4. 10\n5. 9\n6. 10\n7. 8\n8. 10\n9. 9\n10. 10\n11. 9\n12. 9\n13. 0\n14. 8\n15. 10\n16. 9\n17. 8\n18. 10\n19. 9\n20. 8\n21. 9\n22. 10\n23. 8\n24. 8\n25. 10\n26. 10\n27. 8\n28. 10\n29. 10\n30. 7\n31. 10\n32. 9\n33. 7\n34. 10\n35. 10\n36. 10\n37. 10\n38. 10\n39. 10\n40. 10\n41. 8\n42. 10\n43. 10\n44. 8\n45. 10\n46. 10\n47. 8\n48. 10\n49. 10\n50. 9\n51. 7\n52. 10\n53. 8\n54. 10\n55. 8\n56. 10\n57. 10\n58. 10\n59. 10\n60. 10\n61. 10\n62. 9\n63. 0\n64. 9\n65. 5\n66. 8\n67. 10\n68. 9\n69. 7\n70. 10\n71. 8\n72. 0\n73. 10\n74. 10\n75. 10\n76. 8\n77. 10\n78. 10\n79. 7\n80. 10\n81. 10\n82. 10\n83. 5\n84. 10\n85. 10\n86. 10\n87. 10\n88. 10\n89. 10\n90. 9\n91. 10\n92. 9\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 10\n\\item 7\n\\item 8\n\\item 10\n\\item 9\n\\item 10\n\\item 8\n\\item 10\n\\item 9\n\\item 10\n\\item 9\n\\item 9\n\\item 0\n\\item 8\n\\item 10\n\\item 9\n\\item 8\n\\item 10\n\\item 9\n\\item 8\n\\item 9\n\\item 10\n\\item 8\n\\item 8\n\\item 10\n\\item 10\n\\item 8\n\\item 10\n\\item 10\n\\item 7\n\\item 10\n\\item 9\n\\item 7\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 8\n\\item 10\n\\item 10\n\\item 8\n\\item 10\n\\item 10\n\\item 8\n\\item 10\n\\item 10\n\\item 9\n\\item 7\n\\item 10\n\\item 8\n\\item 10\n\\item 8\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 9\n\\item 0\n\\item 9\n\\item 5\n\\item 8\n\\item 10\n\\item 9\n\\item 7\n\\item 10\n\\item 8\n\\item 0\n\\item 10\n\\item 10\n\\item 10\n\\item 8\n\\item 10\n\\item 10\n\\item 7\n\\item 10\n\\item 10\n\\item 10\n\\item 5\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 9\n\\item 10\n\\item 9\n\\end{enumerate*}\n",
            "text/plain": [
              " [1] 10  7  8 10  9 10  8 10  9 10  9  9  0  8 10  9  8 10  9  8  9 10  8  8 10\n",
              "[26] 10  8 10 10  7 10  9  7 10 10 10 10 10 10 10  8 10 10  8 10 10  8 10 10  9\n",
              "[51]  7 10  8 10  8 10 10 10 10 10 10  9  0  9  5  8 10  9  7 10  8  0 10 10 10\n",
              "[76]  8 10 10  7 10 10 10  5 10 10 10 10 10 10  9 10  9"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages21_24.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(max.emohelp = ifelse(max.emohelp >= 9, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"max.emohelp\" %in% col_names){\n",
        "  new_col_order <- c(\"max.emohelp\", col_names[col_names != \"max.emohelp\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$max.emohelp==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ max.emohelp, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "AnoN2c2vjSAt",
        "outputId": "619e2c88-e1e4-4972-9771-0a61d3e040a4"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.032967\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.032967\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.010989\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.032967\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ max.emohelp, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.6529     0.0824   7.924 5.848e-12 0.489242   0.8167 90\n",
              "max.emohelp   0.2503     0.1217   2.056 4.263e-02 0.008496   0.4921 90\n",
              "\n",
              "Multiple R-squared:  0.03105 ,\tAdjusted R-squared:  0.02029 \n",
              "F-statistic: 4.229 on 1 and 90 DF,  p-value: 0.04263"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#25+"
      ],
      "metadata": {
        "id": "iSfaiY4yjtUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA"
      ],
      "metadata": {
        "id": "dCgup3CdjwfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages25_63.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "mAM7zXHBjsC9",
        "outputId": "af4fb227-b8d2-48fc-b2f7-2bf5a146cde5"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.114286\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.085714\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.085714\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.085714\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.085714\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.085714\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.085714\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.114286\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)     0.6724    0.08301   8.100 1.911e-09   0.5037   0.8411 34\n",
              "gpa_thresh3_0   0.3946    0.24495   1.611 1.164e-01  -0.1032   0.8924 34\n",
              "\n",
              "Multiple R-squared:  0.1078 ,\tAdjusted R-squared:  0.08153 \n",
              "F-statistic: 2.595 on 1 and 34 DF,  p-value: 0.1164"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTSD"
      ],
      "metadata": {
        "id": "DPAnmIsakuU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages25_63.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "89dv6JtMjsDG",
        "outputId": "4876bb45-be87-4fc6-e260-fa3eb2b623d4"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.085714\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.085714\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.057143\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.028571\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.085714\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.6747    0.08454   7.981 2.671e-09  0.50293   0.8465 34\n",
              "ptsd_score    0.5876    0.24014   2.447 1.972e-02  0.09962   1.0757 34\n",
              "\n",
              "Multiple R-squared:  0.1674 ,\tAdjusted R-squared:  0.1429 \n",
              "F-statistic: 5.988 on 1 and 34 DF,  p-value: 0.01972"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max.emohelp"
      ],
      "metadata": {
        "id": "7cY3dCf3kva4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(data.intake$max.emohelp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "079330a5-16c3-41c2-9e37-00b941d4b603",
        "id": "NqxcKCZnjsDG"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>9</li><li>9</li><li>10</li><li>9</li><li>10</li><li>10</li><li>10</li><li>9</li><li>10</li><li>1</li><li>10</li><li>10</li><li>10</li><li>9</li><li>10</li><li>9</li><li>10</li><li>9</li><li>7</li><li>9</li><li>10</li><li>10</li><li>10</li><li>10</li><li>10</li><li>7</li><li>10</li><li>10</li><li>10</li><li>8</li><li>10</li></ol>\n"
            ],
            "text/markdown": "1. 10\n2. 10\n3. 10\n4. 10\n5. 10\n6. 9\n7. 9\n8. 10\n9. 9\n10. 10\n11. 10\n12. 10\n13. 9\n14. 10\n15. 1\n16. 10\n17. 10\n18. 10\n19. 9\n20. 10\n21. 9\n22. 10\n23. 9\n24. 7\n25. 9\n26. 10\n27. 10\n28. 10\n29. 10\n30. 10\n31. 7\n32. 10\n33. 10\n34. 10\n35. 8\n36. 10\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 9\n\\item 9\n\\item 10\n\\item 9\n\\item 10\n\\item 10\n\\item 10\n\\item 9\n\\item 10\n\\item 1\n\\item 10\n\\item 10\n\\item 10\n\\item 9\n\\item 10\n\\item 9\n\\item 10\n\\item 9\n\\item 7\n\\item 9\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 10\n\\item 7\n\\item 10\n\\item 10\n\\item 10\n\\item 8\n\\item 10\n\\end{enumerate*}\n",
            "text/plain": [
              " [1] 10 10 10 10 10  9  9 10  9 10 10 10  9 10  1 10 10 10  9 10  9 10  9  7  9\n",
              "[26] 10 10 10 10 10  7 10 10 10  8 10"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('ages25_63.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(max.emohelp = ifelse(max.emohelp >= 9, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"max.emohelp\" %in% col_names){\n",
        "  new_col_order <- c(\"max.emohelp\", col_names[col_names != \"max.emohelp\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$max.emohelp==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ max.emohelp, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "qrfxWso_jsDG",
        "outputId": "2049a87c-1185-423b-96f2-751ab00da281"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.057143\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.057143\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ max.emohelp, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   1.0680     0.2316   4.611 5.463e-05   0.5972   1.5387 34\n",
              "max.emohelp  -0.3483     0.2485  -1.402 1.701e-01  -0.8534   0.1567 34\n",
              "\n",
              "Multiple R-squared:  0.04978 ,\tAdjusted R-squared:  0.02183 \n",
              "F-statistic: 1.964 on 1 and 34 DF,  p-value: 0.1701"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Generation students"
      ],
      "metadata": {
        "id": "QaOkrmk4ph6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA"
      ],
      "metadata": {
        "id": "eYk5uT0dpl0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('firstgen.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "EalssJL2kxxe",
        "outputId": "b09b33b9-45fd-4c97-a9c2-079e5ff22491"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.177778\ttest-error:1.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.044444\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[5]\ttrain-error:0.044444\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)     0.7739     0.1106   6.997 1.153e-08   0.5510   0.9969 44\n",
              "gpa_thresh3_0  -0.2311     0.1852  -1.248 2.185e-01  -0.6043   0.1420 44\n",
              "\n",
              "Multiple R-squared:  0.03385 ,\tAdjusted R-squared:  0.01189 \n",
              "F-statistic: 1.558 on 1 and 44 DF,  p-value: 0.2185"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTSD"
      ],
      "metadata": {
        "id": "yAQPnLb3rWjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('firstgen.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "JhkAWZq4rLtk",
        "outputId": "73e7e91a-5a3c-411c-9c3f-d1b4147c3c40"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.066667\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.066667\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.066667\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.044444\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.044444\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.066667\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.4256    0.05823   7.309 4.033e-09   0.3083    0.543 44\n",
              "ptsd_score    1.0405    0.16964   6.133 2.150e-07   0.6986    1.382 44\n",
              "\n",
              "Multiple R-squared:  0.5757 ,\tAdjusted R-squared:  0.566 \n",
              "F-statistic: 37.62 on 1 and 44 DF,  p-value: 2.15e-07"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "has_i.emo.so"
      ],
      "metadata": {
        "id": "C8XoOYmfrzRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('firstgen.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"has_i.emo.so\" %in% col_names){\n",
        "  new_col_order <- c(\"has_i.emo.so\", col_names[col_names != \"has_i.emo.so\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$has_i.emo.so==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ has_i.emo.so, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "U-gChVpVrZXb",
        "outputId": "09dc5f97-1c75-407a-c7ce-d8ebd859c768"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.000000\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ has_i.emo.so, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.66615     0.1280  5.2033 4.914e-06   0.4081   0.9242 44\n",
              "has_i.emo.so  0.06527     0.1828  0.3571 7.227e-01  -0.3031   0.4336 44\n",
              "\n",
              "Multiple R-squared:  0.002895 ,\tAdjusted R-squared:  -0.01977 \n",
              "F-statistic: 0.1275 on 1 and 44 DF,  p-value: 0.7227"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "edu_i.count"
      ],
      "metadata": {
        "id": "X49b8Y0ntBTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('firstgen.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(edu.i_count = ifelse(edu.i_count <= 2, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"edu.i_count\" %in% col_names){\n",
        "  new_col_order <- c(\"edu.i_count\", col_names[col_names != \"edu.i_count\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$edu.i_count==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ edu.i_count, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "Zokm33RXtBFU",
        "outputId": "bf973327-7ea3-487a-eef9-47115344b56f"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.111111\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.022222\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.111111\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ edu.i_count, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.5000     0.1401   3.570 0.0008776  0.21776   0.7823 44\n",
              "edu.i_count   0.2751     0.1788   1.538 0.1311812 -0.08535   0.6355 44\n",
              "\n",
              "Multiple R-squared:  0.04298 ,\tAdjusted R-squared:  0.02123 \n",
              "F-statistic: 2.366 on 1 and 44 DF,  p-value: 0.1312"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Non-First Generation"
      ],
      "metadata": {
        "id": "O7LoyZfmsG8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA"
      ],
      "metadata": {
        "id": "83-hkyvCsK8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('nonfirstgen.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "tJwwqNvNsFvz",
        "outputId": "4aa70448-bede-4a23-b1e9-15be489bd57a"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.117886\ttest-error:0.333333 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.085366\ttest-error:0.333333 \n",
            "[21]\ttrain-error:0.036585\ttest-error:0.333333 \n",
            "[31]\ttrain-error:0.008130\ttest-error:0.333333 \n",
            "[41]\ttrain-error:0.004065\ttest-error:0.333333 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.333333 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.333333 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.333333 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.333333 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.333333 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.333333 \n",
            "Stopping. Best iteration:\n",
            "[6]\ttrain-error:0.097561\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)     0.8251    0.04469  18.464 2.038e-48   0.7371  0.91317 247\n",
              "gpa_thresh3_0  -0.1101    0.08932  -1.233 2.189e-01  -0.2860  0.06582 247\n",
              "\n",
              "Multiple R-squared:  0.006517 ,\tAdjusted R-squared:  0.002495 \n",
              "F-statistic:  1.52 on 1 and 247 DF,  p-value: 0.2189"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('nonfirstgen.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "IzkT61T-sPc4",
        "outputId": "34ee9f66-4f60-494c-82ed-f73e26d7637f"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.101626\ttest-error:0.333333 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.052846\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.020325\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.016260\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.016260\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.016260\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.004065\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[2]\ttrain-error:0.073171\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)   0.5291    0.03148   16.81 8.855e-43   0.4671   0.5911 247\n",
              "ptsd_score    0.8700    0.06923   12.57 2.495e-28   0.7336   1.0063 247\n",
              "\n",
              "Multiple R-squared:  0.4453 ,\tAdjusted R-squared:  0.4431 \n",
              "F-statistic: 157.9 on 1 and 247 DF,  p-value: < 2.2e-16"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "has_i.emo.so"
      ],
      "metadata": {
        "id": "dDUmBKkZscPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('nonfirstgen.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"has_i.emo.so\" %in% col_names){\n",
        "  new_col_order <- c(\"has_i.emo.so\", col_names[col_names != \"has_i.emo.so\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$has_i.emo.so==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ has_i.emo.so, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "HQ6G09QSsVaM",
        "outputId": "4055cdcb-5a0f-4311-95d4-95c01d0d2899"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.004065\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.004065\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.004065\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.004065\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ has_i.emo.so, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)   0.81709    0.04824 16.9383 3.125e-43   0.7221   0.9121 247\n",
              "has_i.emo.so -0.04129    0.07812 -0.5285 5.976e-01  -0.1952   0.1126 247\n",
              "\n",
              "Multiple R-squared:  0.001158 ,\tAdjusted R-squared:  -0.002886 \n",
              "F-statistic: 0.2793 on 1 and 247 DF,  p-value: 0.5976"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "edu.i_count"
      ],
      "metadata": {
        "id": "MqiaqsyGsfx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('nonfirstgen.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(edu.i_count = ifelse(edu.i_count <= 2, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"edu.i_count\" %in% col_names){\n",
        "  new_col_order <- c(\"edu.i_count\", col_names[col_names != \"edu.i_count\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$edu.i_count==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ edu.i_count, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "wFuxlEOwsezK",
        "outputId": "6f0a3883-0cb1-461a-ee87-04d0753e333a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.081301\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.024390\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.020325\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.012195\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.004065\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.004065\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.004065\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.081301\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ edu.i_count, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|)  CI Lower CI Upper  DF\n",
              "(Intercept)   0.7087    0.05596  12.664 1.175e-28  0.598449   0.8189 247\n",
              "edu.i_count   0.1454    0.07578   1.918 5.621e-02 -0.003881   0.2946 247\n",
              "\n",
              "Multiple R-squared:  0.01386 ,\tAdjusted R-squared:  0.009871 \n",
              "F-statistic:  3.68 on 1 and 247 DF,  p-value: 0.05621"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WHITE"
      ],
      "metadata": {
        "id": "K0i701qG2HRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA"
      ],
      "metadata": {
        "id": "uiyoTZ5J2cqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('white.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "rZ5Xb6Qvs8XM",
        "outputId": "3365fca3-290f-43f0-9e64-b57ad3859677"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.136000\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.088000\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.072000\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.032000\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.024000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.016000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.136000\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)     0.7263    0.05539  13.111 3.066e-25   0.6166  0.83590 125\n",
              "gpa_thresh3_0  -0.1679    0.11962  -1.404 1.629e-01  -0.4046  0.06883 125\n",
              "\n",
              "Multiple R-squared:  0.01252 ,\tAdjusted R-squared:  0.004617 \n",
              "F-statistic:  1.97 on 1 and 125 DF,  p-value: 0.1629"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTSD"
      ],
      "metadata": {
        "id": "QNWpjDib20wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('white.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "McXxxwIh2s_v",
        "outputId": "cd05803b-1b5e-4fa1-e436-8970c2247847"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.088000\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.072000\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.056000\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.056000\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.040000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.032000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.024000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.016000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.008000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.088000\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)   0.4809    0.03452  13.929 3.363e-27   0.4126   0.5492 125\n",
              "ptsd_score    0.9614    0.10196   9.429 2.859e-16   0.7596   1.1632 125\n",
              "\n",
              "Multiple R-squared:  0.5267 ,\tAdjusted R-squared:  0.5229 \n",
              "F-statistic: 88.91 on 1 and 125 DF,  p-value: 2.859e-16"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age"
      ],
      "metadata": {
        "id": "QO-geTT_23j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('white.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(age = ifelse(age < 21, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"age\" %in% col_names){\n",
        "  new_col_order <- c(\"age\", col_names[col_names != \"age\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$age==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ age, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "7WcntYy829J2",
        "outputId": "7d71b1e4-4f87-41b6-afc2-7135244c7daf"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.168000\ttest-error:0.500000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.064000\ttest-error:0.500000 \n",
            "[21]\ttrain-error:0.008000\ttest-error:0.500000 \n",
            "[31]\ttrain-error:0.008000\ttest-error:0.500000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "Stopping. Best iteration:\n",
            "[3]\ttrain-error:0.120000\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ age, data = data.intake, weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)  0.74847    0.07434 10.0677 8.036e-18   0.6013   0.8956 125\n",
              "age         -0.07789    0.10113 -0.7702 4.426e-01  -0.2780   0.1223 125\n",
              "\n",
              "Multiple R-squared:  0.004728 ,\tAdjusted R-squared:  -0.003234 \n",
              "F-statistic: 0.5932 on 1 and 125 DF,  p-value: 0.4426"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "edu_i.count"
      ],
      "metadata": {
        "id": "t_l5oF0X27ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('white.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(edu.i_count = ifelse(edu.i_count <= 2, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"edu.i_count\" %in% col_names){\n",
        "  new_col_order <- c(\"edu.i_count\", col_names[col_names != \"edu.i_count\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$edu.i_count==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ edu.i_count, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "AIOkFT5m22tS",
        "outputId": "43676f5b-c26e-4d69-89f7-93424b0cd8a7"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.072000\ttest-error:0.500000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.032000\ttest-error:0.500000 \n",
            "[21]\ttrain-error:0.016000\ttest-error:0.500000 \n",
            "[31]\ttrain-error:0.016000\ttest-error:0.500000 \n",
            "[41]\ttrain-error:0.016000\ttest-error:0.500000 \n",
            "[51]\ttrain-error:0.016000\ttest-error:0.500000 \n",
            "[61]\ttrain-error:0.008000\ttest-error:0.500000 \n",
            "[71]\ttrain-error:0.008000\ttest-error:0.500000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.072000\ttest-error:0.500000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ edu.i_count, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)   0.5813    0.07643   7.605 5.944e-12  0.42998   0.7325 125\n",
              "edu.i_count   0.1820    0.09964   1.827 7.011e-02 -0.01517   0.3792 125\n",
              "\n",
              "Multiple R-squared:  0.0245 ,\tAdjusted R-squared:  0.01669 \n",
              "F-statistic: 3.337 on 1 and 125 DF,  p-value: 0.07011"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASIAN"
      ],
      "metadata": {
        "id": "9dyIxZeF3b6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA"
      ],
      "metadata": {
        "id": "-ykc1KkH3Ysl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('asian.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "8927e3d8-5a9f-45ae-f06d-c8fc60be1ade",
        "id": "JG-qC24V3Ysn"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.178571\ttest-error:1.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.080357\ttest-error:1.000000 \n",
            "[21]\ttrain-error:0.026786\ttest-error:0.500000 \n",
            "[31]\ttrain-error:0.008929\ttest-error:0.500000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[111]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "Stopping. Best iteration:\n",
            "[13]\ttrain-error:0.044643\ttest-error:0.500000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)     0.9326    0.07315  12.750 1.514e-23   0.7877 1.077568 112\n",
              "gpa_thresh3_0  -0.2296    0.11797  -1.946 5.418e-02  -0.4633 0.004193 112\n",
              "\n",
              "Multiple R-squared:  0.03446 ,\tAdjusted R-squared:  0.02584 \n",
              "F-statistic: 3.786 on 1 and 112 DF,  p-value: 0.05418"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTSD"
      ],
      "metadata": {
        "id": "1x7irth83Yso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('asian.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "1028af20-bb23-439f-ef0a-12645837f260",
        "id": "CTcQCUH33Yso"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.107143\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.062500\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.044643\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.026786\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.026786\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.026786\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.008929\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.008929\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.008929\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.008929\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.107143\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)   0.5554    0.05267  10.546 1.786e-18   0.4511   0.6598 112\n",
              "ptsd_score    0.8038    0.10276   7.822 3.134e-12   0.6002   1.0074 112\n",
              "\n",
              "Multiple R-squared:  0.3836 ,\tAdjusted R-squared:  0.3781 \n",
              "F-statistic: 61.18 on 1 and 112 DF,  p-value: 3.134e-12"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age"
      ],
      "metadata": {
        "id": "YrCJJPVO3Ysp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('asian.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(age = ifelse(age < 21, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"age\" %in% col_names){\n",
        "  new_col_order <- c(\"age\", col_names[col_names != \"age\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$age==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ age, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "400529bc-bc25-4105-adf0-c8fa335e9f08",
        "id": "aBOa-0fO3Ysp"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.187500\ttest-error:0.500000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.071429\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.035714\ttest-error:0.500000 \n",
            "[31]\ttrain-error:0.008929\ttest-error:0.500000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.500000 \n",
            "Stopping. Best iteration:\n",
            "[2]\ttrain-error:0.142857\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ age, data = data.intake, weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)  0.90589     0.0900 10.0652 2.321e-17   0.7276   1.0842 112\n",
              "age         -0.09956     0.1193 -0.8349 4.056e-01  -0.3358   0.1367 112\n",
              "\n",
              "Multiple R-squared:  0.006271 ,\tAdjusted R-squared:  -0.002602 \n",
              "F-statistic: 0.697 on 1 and 112 DF,  p-value: 0.4056"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "edu_i.count"
      ],
      "metadata": {
        "id": "ch_AG7X03Ysp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('asian.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(edu.i_count = ifelse(edu.i_count <= 2, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"edu.i_count\" %in% col_names){\n",
        "  new_col_order <- c(\"edu.i_count\", col_names[col_names != \"edu.i_count\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$edu.i_count==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ edu.i_count, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "c708cd04-be9c-47b9-9d73-ebc344178762",
        "id": "g7NpBv1a3Ysp"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.142857\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.035714\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.026786\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.017857\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.008929\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.142857\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ edu.i_count, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF\n",
              "(Intercept)   0.7573    0.08923   8.488 9.895e-14  0.58055   0.9341 112\n",
              "edu.i_count   0.1514    0.11822   1.281 2.030e-01 -0.08285   0.3856 112\n",
              "\n",
              "Multiple R-squared:  0.0138 ,\tAdjusted R-squared:  0.005 \n",
              "F-statistic:  1.64 on 1 and 112 DF,  p-value: 0.203"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RACE OTHER"
      ],
      "metadata": {
        "id": "McoU2h443nDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPA"
      ],
      "metadata": {
        "id": "VgEcWVG-3Z0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('race_other.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"gpa_thresh3_0\" %in% col_names){\n",
        "  new_col_order <- c(\"gpa_thresh3_0\", col_names[col_names != \"gpa_thresh3_0\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$gpa_thresh3_0==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ gpa_thresh3_0, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "fa1160e3-3214-4a35-bf98-54bcd096cf34",
        "id": "Z-9mvS3_3Z0m"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.150943\ttest-error:1.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.150943\ttest-error:1.000000 \n",
            "[21]\ttrain-error:0.113208\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.094340\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.037736\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "Stopping. Best iteration:\n",
            "[7]\ttrain-error:0.132075\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ gpa_thresh3_0, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)    0.82820    0.09776  8.4715 2.307e-11   0.6320    1.024 52\n",
              "gpa_thresh3_0  0.05455    0.25288  0.2157 8.301e-01  -0.4529    0.562 52\n",
              "\n",
              "Multiple R-squared:  0.001247 ,\tAdjusted R-squared:  -0.01796 \n",
              "F-statistic: 0.04652 on 1 and 52 DF,  p-value: 0.8301"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PTSD"
      ],
      "metadata": {
        "id": "piiq5J_C3Z0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('race_other.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(ptsd_score = ifelse(ptsd_score >= 33, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"ptsd_score\" %in% col_names){\n",
        "  new_col_order <- c(\"ptsd_score\", col_names[col_names != \"ptsd_score\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$ptsd_score==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ ptsd_score, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "f7348ffd-b844-49af-a743-f876d94591f9",
        "id": "UYyzZlLk3Z0n"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.094340\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.018868\ttest-error:1.000000 \n",
            "[21]\ttrain-error:0.018868\ttest-error:1.000000 \n",
            "[31]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:1.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.094340\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ ptsd_score, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.5190     0.0755   6.874 7.874e-09   0.3675   0.6705 52\n",
              "ptsd_score    0.9432     0.1372   6.875 7.842e-09   0.6679   1.2185 52\n",
              "\n",
              "Multiple R-squared:  0.4914 ,\tAdjusted R-squared:  0.4816 \n",
              "F-statistic: 47.26 on 1 and 52 DF,  p-value: 7.842e-09"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age"
      ],
      "metadata": {
        "id": "rqkZks5V3Z0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('race_other.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(age = ifelse(age < 21, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"age\" %in% col_names){\n",
        "  new_col_order <- c(\"age\", col_names[col_names != \"age\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$age==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ age, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "99ca15fe-5691-4bd6-ffc7-a0eddb35fff3",
        "id": "AIYQ-5E83Z0o"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.150943\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.037736\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.150943\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ age, data = data.intake, weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept) 0.828656     0.1575 5.26259 2.731e-06   0.5127   1.1446 52\n",
              "age         0.007848     0.1871 0.04194 9.667e-01  -0.3677   0.3834 52\n",
              "\n",
              "Multiple R-squared:  3.707e-05 ,\tAdjusted R-squared:  -0.01919 \n",
              "F-statistic: 0.001759 on 1 and 52 DF,  p-value: 0.9667"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "edu_i.count"
      ],
      "metadata": {
        "id": "xsQdo2aL3Z0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2024)\n",
        "data.intake <- read.csv('race_other.csv')\n",
        "rownames(data.intake) <- data.intake$record_id\n",
        "data.intake$record_id <- NULL\n",
        "data.intake <- data.intake %>%\n",
        "  mutate(edu.i_count = ifelse(edu.i_count <= 2, 1, 0))\n",
        "\n",
        "col_names <- colnames(data.intake)\n",
        "if (\"edu.i_count\" %in% col_names){\n",
        "  new_col_order <- c(\"edu.i_count\", col_names[col_names != \"edu.i_count\"])\n",
        "  data.intake <- data.intake[, new_col_order]}\n",
        "\n",
        "n <- nrow(data.intake)\n",
        "train_rows <- sample(1:n, 0.99 * n, replace = F)\n",
        "train.intake <- xgb.DMatrix(data.matrix(data.intake[train_rows, -1]),\n",
        "                            label = data.intake[train_rows, 1])\n",
        "test.intake <- xgb.DMatrix(data.matrix(data.intake[-train_rows, -1]),\n",
        "                            label = data.intake[-train_rows, 1])\n",
        "\n",
        "params <- list(\n",
        "  objective = \"binary:logistic\",\n",
        "  learning_rate = 0.05,\n",
        "  subsample = 0.9,\n",
        "  colsample_bynode = 1,\n",
        "  max_depth = 10,\n",
        "  scale_pos_weight = 1\n",
        ")\n",
        "\n",
        "fit_xgb <- xgb.train(\n",
        "  params,\n",
        "  data = train.intake,\n",
        "  watchlist = list(train = train.intake, test = test.intake),\n",
        "  eval.metric = \"error\",\n",
        "  early_stopping_rounds = 100,\n",
        "  print_every_n = 10,\n",
        "  nrounds = 10000\n",
        ")\n",
        "\n",
        "pred <- predict(fit_xgb, train.intake)\n",
        "dif <- dim(data.intake)[1] - length(pred)\n",
        "\n",
        "for (x in 1:dif) {\n",
        "  pred <- c(pred, mean(pred))\n",
        "}\n",
        "\n",
        "ipw <- ifelse(data.intake$edu.i_count==1, 1/pred, 1/(1-pred))\n",
        "model <- lm_robust(mh_scale ~ edu.i_count, data=data.intake, weights=ipw)\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "ffe666e2-b25f-4db8-afc0-6a16456e3725",
        "id": "qWcfYJ0D3Z0p"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttrain-error:0.094340\ttest-error:0.000000 \n",
            "Multiple eval metrics are present. Will use test_error for early stopping.\n",
            "Will train until test_error hasn't improved in 100 rounds.\n",
            "\n",
            "[11]\ttrain-error:0.056604\ttest-error:0.000000 \n",
            "[21]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "[31]\ttrain-error:0.018868\ttest-error:0.000000 \n",
            "[41]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[51]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[61]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[71]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[81]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[91]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "[101]\ttrain-error:0.000000\ttest-error:0.000000 \n",
            "Stopping. Best iteration:\n",
            "[1]\ttrain-error:0.094340\ttest-error:0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm_robust(formula = mh_scale ~ edu.i_count, data = data.intake, \n",
              "    weights = ipw)\n",
              "\n",
              "Weighted, Standard error type:  HC2 \n",
              "\n",
              "Coefficients:\n",
              "            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper DF\n",
              "(Intercept)   0.7442     0.1123  6.6247 1.963e-08   0.5188   0.9697 52\n",
              "edu.i_count   0.1349     0.1672  0.8065 4.236e-01  -0.2007   0.4704 52\n",
              "\n",
              "Multiple R-squared:  0.0108 ,\tAdjusted R-squared:  -0.008221 \n",
              "F-statistic: 0.6505 on 1 and 52 DF,  p-value: 0.4236"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNoAnsuu388a"
      },
      "execution_count": 157,
      "outputs": []
    }
  ]
}